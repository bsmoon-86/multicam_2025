{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05061e96",
   "metadata": {},
   "source": [
    "# 서포트 백터 머신 \n",
    "    - 새로운 데이터가 입력되었을때 기존 데이터를 활용해 분류하는 방법 \n",
    "    - 패턴 인식, 자료 분석 등을 위한 지도 학습 모델로 회귀와 분류 문제 해결에 사용이 되는 알고리즘 \n",
    "\n",
    "- 매개변수 \n",
    "    - C\n",
    "        - 기본값 : 1.0 \n",
    "        - 규제의 강도의 역수\n",
    "        - 숫자가 크면 -> 오차를 허용하지 않는다 (과적합 위험)\n",
    "        - 숫자가 작으면 -> 오차를 어느정도 허용(일반화 위험)\n",
    "    - kernel (커널 함수의 종류)\n",
    "        - 기본값 : \"rbf\"\n",
    "        - 실제의 데이터가 선형이 아닌 경우 커널 함수를 이용하여 데이터를 고차원 공간으로 매핑하여 직선으로 구분을 가능하게 하는 방법 \n",
    "        - \"linear\" : 선형 SVM\n",
    "        - \"poly\" : 다항식 커널\n",
    "        - 'rbf' : 가우시안 커널(가장 많이 사용)\n",
    "        - \"sigmoid\" : 시그모이드 함수 기반 \n",
    "    - gamma\n",
    "        - 커널 계수\n",
    "        - 'linear' 제외한 커널이 선택되었을때 사용\n",
    "        - 크면 -> 경계가 복잡해짐 (과적합 위험)\n",
    "        - 작으면 -> 경계가 유연해짐 (일반화 위험)\n",
    "    - degree\n",
    "        - 기본값 : 3\n",
    "        - 다항식 커널의 차수 \n",
    "        - 비선형 데이터의 패턴을 학습할수 있게 해주는 변수 \n",
    "    - probability\n",
    "        - 기본값 : False\n",
    "        - 확률 출력의 여부 -> True인 경우 predict_proba() 함수를 사용 가능 \n",
    "        - 학습할때 속도가 느려짐 \n",
    "- 주요 속성\n",
    "    - support_ \n",
    "        - 서포트 백터의 인덱스의 값\n",
    "        - 전체의 데이터에서 경계선에 딱 붙어 있는 데이터의 인덱스 값\n",
    "    - support_vectors_\n",
    "        - support_ 위치(인덱스)의 값이라면 그 값에 해당하는 실제 데이터 값\n",
    "    - n_support_\n",
    "        - 클래스(컬럼)별 서포트 백터의 개수 \n",
    "    - coef_\n",
    "        - 결정 경계의 계수 (linear 커널인 경우에만 사용 가능)\n",
    "- 메서드 \n",
    "    - fit(x, y) : 학습\n",
    "    - predict(x) : 예측\n",
    "    - predict_proba(x) : 예측 확률(probability의 값이 True인 경우)\n",
    "    - decision_function(x) : 결정 함수의 값(margin과의 거리)\n",
    "    - score(x, y) : 정확도 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48494b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,\\\n",
    "    recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5226b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 클래스 분포를 그래프 확인 \n",
    "sns.pairplot(\n",
    "    data = df, \n",
    "    hue = 'success'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 분할 train, test\n",
    "x = df[['age', 'interest']].values\n",
    "y = df['success'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3, stratify=y, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 사용 \n",
    "# SVM은 각각 특성(컬럼)의 스케일에 매우 민감하기 때문에 스케일링 필요 \n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링이 된 데이터를 기준으로 학습하고 평가 \n",
    "clf = SVC(C=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_sc, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test_sc)\n",
    "\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "acc = accuracy_score(Y_test, pred)\n",
    "prc = precision_score(Y_test, pred)\n",
    "rcll = recall_score(Y_test, pred)\n",
    "f1 = f1_score(Y_test, pred)\n",
    "print(\"혼동행렬 : \", cm)\n",
    "print('정확도 : ', round(acc, 2))\n",
    "print('정밀도 : ', round(prc, 2))\n",
    "print('재현율 : ', round(rcll, 2))\n",
    "print('F1 : ', round(f1*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링이 되지 않은 원본의 데이터를 이용하여 학습 평가 지표 출력 \n",
    "\n",
    "clf2 = SVC(C=0.5)\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "pred2 = clf2.predict(X_test)\n",
    "\n",
    "cm_2 = confusion_matrix(Y_test, pred2)\n",
    "acc_2 = accuracy_score(Y_test, pred2)\n",
    "prc_2 = precision_score(Y_test, pred2)\n",
    "rcll_2 = recall_score(Y_test, pred2)\n",
    "f1_2 = f1_score(Y_test, pred2)\n",
    "print(\"혼동행렬 : \", cm_2)\n",
    "print('정확도 : ', round(acc_2, 2))\n",
    "print('정밀도 : ', round(prc_2, 2))\n",
    "print('재현율 : ', round(rcll_2, 2))\n",
    "print('F1 : ', round(f1_2*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 분석을 통하여 확인 \n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마진 영역을 그래프로 표시 \n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i, c in enumerate([1, 500]):\n",
    "    # i에는 [1, 500] 리스트의 위치 값이 순차적으로 대입 \n",
    "    # c에는 [1, 500] 리스트의 값들이 순차적으로 대입 \n",
    "    clf = LinearSVC(C = c, random_state=42)\n",
    "    clf.fit(X_train_sc, Y_train)\n",
    "\n",
    "    # decision_function() -> 경계선과의 거리를 의미 \n",
    "    decision = clf.decision_function(X_train_sc)\n",
    "\n",
    "    # margin(-1 <= decision_function() <= 1) 의 데이터를 support_vector로 간주 \n",
    "    support_vactor_indices = np.where(\n",
    "        np.abs( decision ) <= 1 + 1e-15\n",
    "    )[0]\n",
    "    support_vector = X_train_sc[support_vactor_indices]\n",
    "    # support_vector의 개수를 출력 \n",
    "    print(f\"C -> {c}인 경우 support_vector의 개수는 {len(support_vector)}\")\n",
    "\n",
    "    # subplot을 이용하여 1행 2열의 영역을 생성 \n",
    "    plt.subplot(1, 2, i+1)\n",
    "\n",
    "    # 학습 데이터의 산점도 그래프를 생성 \n",
    "    plt.scatter(X_train_sc[:, 0], X_train_sc[:, 1], c = Y_train, cmap=plt.cm.Paired)\n",
    "\n",
    "    # 현재 좌표축의 정보를 로드 \n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    #  격자(결정 경계) 추가 \n",
    "    xx, yy = np.meshgrid(\n",
    "        # x축 범위 안에서 50개의 데이터를 생성 \n",
    "        np.linspace(xlim[0], xlim[1], 50), \n",
    "        # y축 범위 안에서 50개의 데이터를 생성\n",
    "        np.linspace(ylim[0], ylim[1], 50)\n",
    "    )\n",
    "\n",
    "    # 각 격자점에 대한 desicion_function의 값을 지정하고 행렬의 크기를 xx와 같게 변환\n",
    "    z = clf.decision_function( np.c_[xx.ravel(), yy.ravel()] )\n",
    "    z = z.reshape(xx.shape)\n",
    "\n",
    "    # 등고선을 추가 \n",
    "    # 결정 경계와 margin을 생성 \n",
    "    plt.contour(\n",
    "        xx, yy, z, colors='k', levels=[-1, 0, 1], # levels -> -1, 1은 margins, 0은 결정 경계\n",
    "        alpha = 0.5, linestyles = ['--', '-', '--']\n",
    "    )\n",
    "\n",
    "    # support_vector의 데이터를 동그라미 표시 \n",
    "    plt.scatter(\n",
    "        support_vector[:, 0], support_vector[:, 1], \n",
    "        s = 100, # 크기 \n",
    "        linewidths=1, facecolors = 'none', edgecolors= 'k'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44672ad5",
   "metadata": {},
   "source": [
    "# SVR (Support Vector Refression)\n",
    "- 서포트 백터 회귀 분석 \n",
    "- 입실론 튜브 안에 들어오는 데이터는 오차로 보지 않는다. \n",
    "- 튜브 밖의 데이터만 패널티를 부여 하는 방식 \n",
    "\n",
    "- 매개변수 \n",
    "    - kernel \n",
    "        - 커널 함수 선택 \n",
    "        - linear\n",
    "            - 사용 매개변수 : C, epsilron\n",
    "            - 고차원 희소데이터, 선형 데이터셋\n",
    "        - rbf\n",
    "            - 사용 매개변수 : C, epsilron, gamma\n",
    "            - 범용, 성능이 우수 \n",
    "        - poly\n",
    "            - 사용 매개변수 : C, epsilron, degree, gamma\n",
    "            - 다항적 경계가 자연스러운 데이터 \n",
    "        - sigmoid \n",
    "            - 사용 매개변수 : C, esilron, gamma\n",
    "            - 특수한 경우에 이용, 신경망과 유사 데이터 (연구용 데이터)\n",
    "    - esilron : 오차 허용의 폭\n",
    "    - gamma : 데이터 간 영향의 범위 \n",
    "- 속성\n",
    "    - dual_coef_ : 쌍대 문제의 알파 값들 \n",
    "    - coef_ : 회귀 계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 데이터를 생성 \n",
    "x = np.sort(\n",
    "    5 * np.random.rand(40, 1), axis=0\n",
    ")\n",
    "y = np.sin(x).ravel()\n",
    "\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 데이터(종속변수에 노이즈 추가)\n",
    "y[::5] += 3*(0.5-np.random.rand(8))\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델에 (rbf, 선형, 다항)\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto', epsilon=0.1)\n",
    "svr_poly = SVR(kernel='poly', C=100, degree=3, gamma='auto', epsilon=0.1, coef0=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49860f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea38d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 \n",
    "svr_rbf.fit(x, y)\n",
    "svr_lin.fit(x, y)\n",
    "svr_poly.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8946d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 데이터를 생성 \n",
    "pred_rbf = svr_rbf.predict(x)\n",
    "pred_lin = svr_lin.predict(x)\n",
    "pred_poly = svr_poly.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표를 데이터프레임으로 생성\n",
    "index = ['RBF', 'Lin', 'Poly']\n",
    "cols = ['MSE', 'RMSE', 'MAE', 'R2']\n",
    "result = pd.DataFrame(index = index, columns = cols)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4527fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 값들을 리스트로 생성 \n",
    "preds = [pred_rbf, pred_lin, pred_poly]\n",
    "\n",
    "for pred, i in zip(preds, index):\n",
    "    # pred -> 예측값 -> 타입이 1차원 배열\n",
    "    # i -> kernel의 값\n",
    "    mse = mean_squared_error(y, pred)\n",
    "    mae = mean_absolute_error(y, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y, pred)\n",
    "\n",
    "    result.loc[i, 'MSE'] = mse\n",
    "    result.loc[i, 'MAE'] = mae\n",
    "    result.loc[i, 'RMSE'] = rmse\n",
    "    result.loc[i, 'R2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3330cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston 데이터를 이용하여 SVR의 RBF, Lin, Poly 모델중 어떤것이 성능이 가장 높은가? 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc282c16",
   "metadata": {},
   "source": [
    "# 연습 \n",
    "- csv 폴더 안에 boston 데이터를 로드 \n",
    "- 독립 , 종속 변수로 데이터를 나눠준다. \n",
    "- train, test를 8:2의 비율로 분할 \n",
    "- RBF, Lin, Poly 모델을 생성\n",
    "- train 데이터를 학습 \n",
    "- test데이터를 이용하여 예측 \n",
    "- 각각 모델의 평가 지표를 생성하여 우수한 kernel함수를 선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(\"../csv/boston.csv\")\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수 / 종속 변수 \n",
    "x = boston.drop('Price', axis=1).values\n",
    "y = boston['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0a4e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터셋 분할 8:2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size= 0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c6c5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto', epsilon=0.1)\n",
    "svr_poly = SVR(kernel='poly', C=100, degree=3, gamma='auto', epsilon=0.1, coef0=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 \n",
    "svr_rbf.fit(X_train, Y_train)\n",
    "svr_lin.fit(X_train, Y_train)\n",
    "svr_poly.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
