{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aa0c3a",
   "metadata": {},
   "source": [
    "#### SBERT\n",
    "- BERT 모델 : 문장 이해용 Encoder\n",
    "    - 문장 쌍 비교\n",
    "- SBERT 모델 : 문장 의미 임베딩 \n",
    "    - 벡터의 비교용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a04320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d75b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 로드 -> 두개의 문장을 비교(코사인 유사도)\n",
    "# 다목적 한국 SBERT\n",
    "model_name = 'jhgan/ko-sroberta-multitask'\n",
    "# 문장 유사도 특화 \n",
    "model_name2 = 'BM-K/KoSimCSE-roberta-multitask'\n",
    "\n",
    "sbert = SentenceTransformer(model_name)\n",
    "sbert2 = SentenceTransformer(model_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1433e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 토큰의 길이를 설정 \n",
    "sbert.max_seq_length = 256\n",
    "sbert2.max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f633904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 문장을 비교 \n",
    "doc1 = \"이 카메라는 색감이 자연스럽고 배터리도 오래간다\"\n",
    "doc2 = \"배터리 성능이 좋고 사진 품질이 뛰어나다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609188e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 :  0.6948\n"
     ]
    }
   ],
   "source": [
    "# 두개의 문장을 임베딩 -> 코사인 유사도 계산 \n",
    "# sbert인 경우 \n",
    "with torch.inference_mode():\n",
    "    emb1 = sbert.encode(doc1, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb2 = sbert.encode(doc2, convert_to_tensor=True, normalize_embeddings=True)\n",
    "# 코사인 유사도 계산\n",
    "cos_sim = util.cos_sim(emb1, emb2).item()\n",
    "print(\"유사도 : \", round(cos_sim, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6dcc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 :  0.734\n"
     ]
    }
   ],
   "source": [
    "# 두개의 문장을 임베딩 -> 코사인 유사도 계산 \n",
    "# sbert2인 경우 \n",
    "with torch.inference_mode():\n",
    "    emb1 = sbert2.encode(doc1, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb2 = sbert2.encode(doc2, convert_to_tensor=True, normalize_embeddings=True)\n",
    "# 코사인 유사도 계산\n",
    "cos_sim = util.cos_sim(emb1, emb2).item()\n",
    "print(\"유사도 : \", round(cos_sim, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd0523a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db7e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.3585, 0.0140],\n",
      "        [0.3585, 1.0000, 0.1416],\n",
      "        [0.0140, 0.1416, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    '삼성전자 주가가 올랐다', \n",
    "    \"코스피가 상승 마감했다\", \n",
    "    '비가 많이 와서 항공편이 취소됬다'\n",
    "]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    embs = sbert2.encode(sentences, convert_to_tensor=True, \n",
    "                         normalize_embeddings=True)\n",
    "\n",
    "# 3개의 문장에서의 유사도를 확인 \n",
    "sim_metrix = util.cos_sim(embs, embs)\n",
    "print(sim_metrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36883511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6161, 0.6014]),\n",
       "indices=tensor([0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence = \"증시가 강세였다\"\n",
    "# 임베딩 \n",
    "new_emb = sbert2.encode(new_sentence, convert_to_tensor=True, \n",
    "                        normalize_embeddings=True)\n",
    "# 유사도가 높은 상위의 n개 확인 \n",
    "top_n = 2\n",
    "hits = torch.topk(\n",
    "    util.cos_sim(new_emb, embs).squeeze(0), k = top_n\n",
    ")\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d3e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자 주가가 올랐다 | score : 0.616\n",
      "코스피가 상승 마감했다 | score : 0.601\n"
     ]
    }
   ],
   "source": [
    "for score, idx in zip( hits.values.tolist(), hits.indices.tolist() ):\n",
    "    print(f\"{sentences[idx]} | score : {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994874c",
   "metadata": {},
   "source": [
    "### 연습 \n",
    "- ratings_train.txt 파일을 로드 \n",
    "- 결측치 제거 \n",
    "- document 컬럼의 문자 정규화(특수문자 제거, 2칸 이상의 공백 제거, 좌우 공백 제거) \n",
    "- 중복 document 제거 , 글자의 수가 1개 이하인 행은 제거  \n",
    "- DataFrame에서 sample(n = 10000, random_state=42)로 임의의 데이터를 추출하여 저장 (head() -> 상위 데이터 | tail() -> 하위 데이터 | sample() -> 무작위 데이터) \n",
    "- train, test 셋으로 8:2 로 데이터분할\n",
    "- sbert 모델은 'BM-K/KoSimCSE-roberta-multitask'을 이용\n",
    "- Dataset을 정의 (Trainer 이용하지 않고 Dataset과 DataLoader 사용)\n",
    "    - `__init__(self, document, labels)`\n",
    "        - 입력받은 document와 labels를 document는 SBERT 모델을 이용하여 인코딩 \n",
    "        - labels 데이터를 tensor형태로 변환 \n",
    "    - `__len__(self)` 함수는 라벨의 길이를 되돌려준다\n",
    "    - `__getitem__(self, idx)` 함수는 인코딩된 데이터[idx], label[idx]를 되돌려준다\n",
    "- Dataset를 train, test를 이용해서 Dataset을 생성 \n",
    "- DataLoarder를 이용하여 배치의 사이즈는 128 shuffle은 True 구성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d39531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb33df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 \n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f62c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 제거 \n",
    "df.dropna(subset='document', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7043ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = re.sub(r'[^가-힣0-9a-zA-Z\\s\\.]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670ccf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['document'] = df['document'].map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c67680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터를 제거 \n",
    "df.drop_duplicates(subset='document', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3e1434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144734"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3243a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열의 길이가 1 이하는 제거 -> 1초과인 데이터만 확인 \n",
    "flag = df['document'].str.len() > 1\n",
    "df = df.loc[flag,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ed8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤한 데이터 10000개추출 sample()\n",
    "df = df.sample(n = 10000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20c1f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할 (8:2)\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63987ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4006\n",
       "1    3994\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f42e804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "model_name3 = 'BM-K/KoSimCSE-roberta-multitask'\n",
    "sbert3 = SentenceTransformer(model_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6a6def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 정의 \n",
    "class SBERTDataset(Dataset):\n",
    "    # 생성자 함수 -> document, labels 받아와서 document 임베딩, labels는 tensor화\n",
    "    def __init__(self, document, labels):\n",
    "        # no_grad() -> 자동 미분 일시 정지 \n",
    "        # inference_mode() -> 추론 모드 \n",
    "        with torch.inference_mode():\n",
    "            # 로드한 모델을 이용해서 encode 작업 \n",
    "            # convet_to_tensor -> 결과값을 tensor로 받을것인가? (False : list)\n",
    "            # normalize_embeddings -> L2 정규화 할것인가?\n",
    "            self.emb = sbert3.encode(\n",
    "                document, convert_to_tensor = True, normalize_embeddings=True\n",
    "            )\n",
    "        # labels를 tensor화 \n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        # labels의 길이를 되돌려준다.\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.emb[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66efdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset의 형태로 데이터프레임을 변환 \n",
    "train_ds = SBERTDataset( train_df['document'].tolist(), train_df['label'].tolist() )\n",
    "test_ds = SBERTDataset(test_df['document'].tolist(), test_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d2bd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader를 이용해서 배치 사이즈만큼의 데이터를 생성 \n",
    "train_dl = DataLoader(train_ds, batch_size = 128, shuffle = True)\n",
    "test_dl = DataLoader(test_ds, batch_size = 128, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
