{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05459032",
   "metadata": {},
   "source": [
    "# LSTM (장기 의존성 학습 모델)\n",
    "- RNN 구조에서 발생하는 문제를 해결하기 위해 구조를 변경한 모델 \n",
    "- 기존의 RNN은 학습의 횟수가 증가하면 과거의 기억이 잃는다. \n",
    "    - 반복 학습을 하면서 가중치의 변화량이 0에 가까워짐을 의미 \n",
    "    - 손실 함수 -> tanh -> 반복적으로 tanh() 함수를 실행하게 되면 변화량 0\n",
    "- LSTM은 반복 학습을 하면서 과거의 기억 중 장기 기억과, 단기 기억으로 나눠주는 역할\n",
    "    - 반복 학습을 하면서 tanh() 중복적으로 실행이 되면 기울기 변화량 줄어듬.\n",
    "    - 장기 기억은 tank() 함수를 실행하지 않고 -> 가중치의 변화를 계속 주겠다.\n",
    "    - 셀이라는 공간에 장기 기억 정보를 전달 \n",
    "    - 게이트로 정도를 선택적으로 보관, 삭제, 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d730ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7afbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드 \n",
    "df = pd.read_csv(\"../csv/AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date 컬럼의 dtype을 시계열 데이터로 변환 \n",
    "# 문자형 데이터를 시계열 데이터로 변환 -> \n",
    "# 그래프 시각화할때 X축의 데이터로 사용하기 위함\n",
    "df['Date'] = pd.to_datetime(\n",
    "    df['Date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a82eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 컬럼 선택 \n",
    "df = df[['Date', 'Adj Close', 'Volume']]\n",
    "# 결측치가 포함되어있는 행을 모두 제거 \n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4233ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 데이터, 종속 데이터를 생성 \n",
    "X_all = df[['Adj Close', 'Volume']]\n",
    "Y_all = df[['Adj Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1444d659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7770, 2) (1943, 2)\n",
      "(7770, 1) (1943, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 8:2 비율로 나눠준다. \n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X_all[ : split_idx], X_all[split_idx : ]\n",
    "Y_train, Y_test = Y_all[ : split_idx], Y_all[split_idx : ]\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecc802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 설정 값\n",
    "# 시계열 데이터의 구간(과거 데이터의 개수)\n",
    "window = 60\n",
    "# 학습 루프에서 루프의 수 \n",
    "epochs = 20\n",
    "# 학습 데이터의 배치의 개수\n",
    "x_batch = 64\n",
    "# optimizer lr 값 (학습율)\n",
    "lr = 0.001\n",
    "# 은닉 층의 뉴런의 개수 \n",
    "hidden_cnt = 64\n",
    "# 랜덤의 일반화\n",
    "torch.manual_seed(42)\n",
    "# 은닉층, 셀 사용 여부\n",
    "head_type = 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28343316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    # 입력 데이터와 타깃 데이터를 받아서 \n",
    "    # 구간의 수만큼 입력데이터를 잘라주고 \n",
    "    # 해당 구간 바로 다음 행의 타깃 데이터를 생성\n",
    "    # 구간의 데이터와 다음행의 타깃 데이터를 되돌려준다\n",
    "    # DataLoader 클래스에서 사용하기 위함\n",
    "    def __init__(\n",
    "            self, _x, _y, _window\n",
    "    ):\n",
    "        self.x = _x\n",
    "        self.y = _y\n",
    "        self.window = _window\n",
    "        # n의 값은 구간의 데이터 시작 지점의 최대값\n",
    "        self.n = len(_x) - _window\n",
    "    \n",
    "    def __len__(self):\n",
    "        # window 의 수치가 x의 길이보다 큰 경우에는 1을 되돌려준다. \n",
    "        return max(self.n, 1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # idx : 구간의 시점 지점 -> 최대 값은 self.n\n",
    "        # idx부터 idx+window-1 지점까지의 데이터 -> (window, 2)\n",
    "        x_window = self.x[idx : idx + self.window]\n",
    "        # idx+window 위치의 데이터  -> 단일값 생성\n",
    "        y_next = self.y[idx + self.window]\n",
    "        # tensor형의 변환 \n",
    "        x_tensor = torch.from_numpy(x_window)\n",
    "        y_tensor = torch.from_numpy(y_next)\n",
    "\n",
    "        return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac05ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터들 스케일링 -> MinMaxScaler\n",
    "x_scaler = MinMaxScaler().fit(X_train)\n",
    "y_scaler = MinMaxScaler().fit(Y_train)\n",
    "\n",
    "X_train = x_scaler.transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "Y_train = y_scaler.transform(Y_train)\n",
    "Y_test = y_scaler.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9417e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WindowDataset 생성 \n",
    "# 객체을 생성하고 getitem() 함수를 사용한다면 window(60) 구간의 데이터와\n",
    "# 해당 구간 다음 행의 종가 데이터를 되돌려주는 class\n",
    "train_ds = WindowDataset(X_train, Y_train, window)\n",
    "test_ds = WindowDataset(X_test, Y_test, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6ad7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader -> WindowDataset  class를 이용하여 \n",
    "# ds_data에서 len() 함수를 이용하여 해당 구간에서 가장 마지막에 사용 가능한 시작 지점\n",
    "\n",
    "train_dl = DataLoader(train_ds, shuffle=True, drop_last= True, \n",
    "                      batch_size=x_batch)\n",
    "test_dl = DataLoader(test_ds, shuffle=False, drop_last = False, \n",
    "                     batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bac1cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for x, y in test_dl:\n",
    "#     print(\"구간 데이터 : \",x)\n",
    "#     # print(\"다음 날의 종가 :\", y)\n",
    "#     if i == 2 : \n",
    "#         break\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8056b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의 \n",
    "\n",
    "class LSTMReg(nn.Module):\n",
    "    # h : 마지막의 은닉층의 데이터를 이용 (RNN -> 기억 소실 , LSTM -> 장기 적인 기억은 유지)\n",
    "    # c : 셀의 데이터를 이용 \n",
    "    # h_c : 은닉층 + 셀의 데이터를 이용\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size, hidden_size, \n",
    "            num_layers = 1, dropout = 0.0, \n",
    "            bidirectional = False, head_type = 'h'\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # lstm 기본 설정 \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_size, \n",
    "            hidden_size= hidden_size, \n",
    "            num_layers= num_layers, \n",
    "            dropout= dropout, \n",
    "            bidirectional= bidirectional\n",
    "        )\n",
    "\n",
    "        # bidirectional이 True인 경우 차원의 개수 * 2\n",
    "        out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        # head_type은 은닉층만 사용하거나 셀만 사용 -> 차원의 개수 * 1 \n",
    "        if head_type in ['h', 'c']:\n",
    "            head_in = out_dim\n",
    "        elif head_type == 'h_c':\n",
    "            head_in  = out_dim * 2\n",
    "        else:\n",
    "            print('head_type Error')\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(head_in, 1)\n",
    "        )\n",
    "        self.head_type = head_type\n",
    "    \n",
    "    # 순전파 함수 \n",
    "    def forward(self, x):\n",
    "        # 순전파의 예측 결과 값\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        # 은닉층 중 마지막 은닉층을 저장 \n",
    "        h_last = h_n[-1]\n",
    "        # 셀 마지막 셀 \n",
    "        c_last = torch.tanh(c_n[-1])\n",
    "\n",
    "        if self.head_type == 'h':\n",
    "            feat = h_last\n",
    "        elif self.head_type == 'c':\n",
    "            feat = c_last\n",
    "        elif self.head_type == 'h_c':\n",
    "            feat = torch.cat( [h_last, c_last], dim = -1 )\n",
    "        \n",
    "        return self.head(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb695e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMReg(\n",
       "  (lstm): LSTM(2, 64)\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMReg(input_size=2, hidden_size=hidden_cnt, \n",
    "                head_type=head_type)\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
