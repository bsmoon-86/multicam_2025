{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059faade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d105285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "print(okt.morphs('나는 학교에 간다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104de7e",
   "metadata": {},
   "source": [
    "# 데이터의 분할\n",
    "- KFold의 분할 방식 \n",
    "    - KFold\n",
    "        - 무작위로 데이터를 폴드화 \n",
    "    - StratifiedKFold\n",
    "        - 계층화를 유지하면서 폴드화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "data = {\n",
    "    'document' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],\n",
    "    'label' : [1, 1, 0, 0, 1, 0, 0, 1], \n",
    "    'id' : ['a', 'a', 'b', 'b', 'c', 'c', 'd', 'd']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fcd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 KFold \n",
    "X = df['document']\n",
    "Y = df['label']\n",
    "groups = df['id']\n",
    "\n",
    "k_folds = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "s_folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "sg_fold = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da057f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_idx, y_idx in k_folds.split(X, Y):\n",
    "    print(df.loc[x_idx])\n",
    "    print(df.loc[y_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층화 KFold\n",
    "for x_idx, y_idx in s_folds.split(X, Y):\n",
    "    print(df.loc[x_idx])\n",
    "    print(df.loc[y_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e058801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층별 그룹화 KFold\n",
    "for x_idx, y_idx in sg_fold.split(X, Y, groups):\n",
    "    print(df.loc[x_idx])\n",
    "    print(df.loc[y_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 영화 리뷰 (rating_train.txt)파일 \n",
    "# pandas를 이용하여 txt 파일을 로드 \n",
    "# 파일을 로드하는데 데이터 간의 분리법은 tab으로 이루어져있다. \n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정보를 확인 \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa505f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info()를 통해서 document 컬럼의 결측치가 확인 -> 5개\n",
    "# 150000개에서 5개의 데이터는 제거 가능 \n",
    "# case1 (isna() + any() -> 인덱스의 조건식으로 해당 조건을 부정하여 사용)\n",
    "df.loc[~df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document가 같은 문장이라면 문장을 하나만 두고 나머지는 제거 \n",
    "# 중복 데이터가 존재하는가?\n",
    "df['document'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4867fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 데이터는 제거 \n",
    "# 제거하기 전의 데이터의 개수 \n",
    "before = len(df)\n",
    "# drop_duplicates() : 데이터의 중복을 제거하는 함수\n",
    "df = df.drop_duplicates(['document']).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(\"중복 데이터 제거한 행의 개수 : \", before - after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900be635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id 컬럼의 유일한 데이터들의 길이를 확인 \n",
    "print(len(\n",
    "    df['id'].unique()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a30478",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 컬럼의 데이터의 개수를 확인 \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test 데이터셋으로 8:1:1 정도의 비율로 데이터를 분할\n",
    "# label의 비율에 맞게 데이터를 나눠준다. \n",
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn에는 3개의 데이터셋으로 나눠주는 함수를 존재x\n",
    "# train_test_split를 2번 사용\n",
    "X = df['document'].values\n",
    "Y = df['label'].values\n",
    "# test 데이터셋을 10%로 먼저 나눠준다. \n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=42, stratify=Y\n",
    ")\n",
    "# validation 데이터셋을 11% 정도로 나눠준다. (label데이터의 비율에 맞게)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.11, random_state=42, stratify=Y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f825a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 분할 정도를 확인\n",
    "print(len(X_train) / len(X) * 100)\n",
    "print(len(X_val) / len(X) * 100)\n",
    "print(len(X_test) / len(X) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e45b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(Y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b18b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(Y_val).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a83049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층 폴드화 -> 학습 데이터를 데이터를 분할/학습하여 일반적인 성능을 나타내는 방법\n",
    "# 폴드화, 하이퍼 파라미터 탐색과 같이 사용\n",
    "folds = []\n",
    "# enumerate() -> 리스트에서 위치와 값으로 데이터를 나눠서 되돌려준다. \n",
    "# s_folds.split(X_train, Y_train) -> 결과 값이 ( (tr_idxs, va_idxs) )\n",
    "for fold, (tr_idx, va_idx) in enumerate(\n",
    "    s_folds.split(X_train, Y_train)):\n",
    "    folds.append(\n",
    "        {\n",
    "            'fold' : fold, \n",
    "            'tr_idx' : tr_idx, \n",
    "            'va_idx' : va_idx\n",
    "        }\n",
    "    )\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold에서 첫번째 데이터에서 tr_idx 가지고 Y_train의 0,1의 비율을 확인 \n",
    "test_idx = folds[0]['tr_idx']\n",
    "pd.Series(Y_train[test_idx]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b6a39",
   "metadata": {},
   "source": [
    "# 단어의 토큰화 \n",
    "- 문장을 단어로 잘라준다. \n",
    "    - 공백을 기준으로 문자를 자른다. \n",
    "        -영문에서는 사용 가능, 한글에서는 의미가 소실되는 경우가 발생 \n",
    "    - 형태소를 사용하여 문자를 나눠준다. \n",
    "        - 국어 사전을 로드하여 단어별로 나눠준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백을 기반으로 데이터를 나눈다. \n",
    "text = '나는 학교에 간다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace490cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ade27",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Hello World\"\n",
    "tokens2 = text2.split()\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(text)) # 단어별로 나눠주는 함수\n",
    "text_pos = okt.pos(text)\n",
    "print(okt.pos(text))    # 단어와 단어의 종류를 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f517720",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos.remove( ('는','Josa') )   # 하나씩 정리하는 방법 ( 매우 귀찬 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복문을 이용하여 각원소들을 대입하여 실행 \n",
    "for t in text_pos:\n",
    "    # print(t)\n",
    "    # t -> tuple -> 두번째 값이 'Josa'가 아니라면\n",
    "    if t[1] != 'Josa':\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c602f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt 로드한 데이터를 이용하여 Okt 형태소 분석 \n",
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    _pos = okt.morphs(t)\n",
    "    print(_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4194fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Korpora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Korpora import Korpora \n",
    "# data = Korpora.load('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4303434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소를 이용한 토큰화 \n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece 모듈을 이용하여 형태소 분석 \n",
    "# 모델 학습 \n",
    "# train txt, test txt 파일을 모두 로드하여 학습에 대입 \n",
    "df_tr = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t').dropna()\n",
    "df_te = pd.read_csv(\"../data/ratings_test.txt\", sep='\\t').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 데이터프레임을 단순 행결합(union 결합)\n",
    "total_df = pd.concat( [df_tr['document'], df_te['document']], \n",
    "                     axis=0, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13bbabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 학습 시키기 전에 파일로 미리 저장 \n",
    "total_df.to_csv('test.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성 \n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input = 'test.txt',     # 학습에서 사용할 텍스트 파일\n",
    "    model_prefix = 'ko_unigram', # unigram -> 한글 적합한 형태 (한단어씩 잘라서 표현) -> 모델명\n",
    "    vocab_size = 8000,  # 단어 사전의 크기(모델의 크기) -> 8000, 16000, 32000\n",
    "    model_type = 'unigram',     # 토큰의 생성 방식 \n",
    "                                # unigram -> BERT, KoGPT등에서 사용이 되는 언어 모델 방식\n",
    "                                # bpe -> GPT-2 사용하는 방식 (한글에서는 부적합)\n",
    "                                # char -> 문자 단위( 정보가 너무 짧게 쪼개져 있는 형태 )\n",
    "                                # word -> 단어 단위(한국어에 부적합)\n",
    "    character_coverage = 0.9995,    # 학습에 포한할 문자의 종류의 비율\n",
    "                                    # 1.0 인 경우 모든 문자의 종류를 사용\n",
    "                                    # 0.9995 -> 한글, 영문, 숫자 포함 \n",
    "    input_sentence_size =  100000, # 학습 문장을 샘플링 \n",
    "                                    # 모든 데이터를 사용하는게 제일 좋은 방법(시간이 오래 걸림)\n",
    "                                    # 일부만 샘플링하여 사용하는 방법\n",
    "    shuffle_input_sentence = True   # 샘플링시 문장의 순서를 섞어서 사용\n",
    "                                    # 모델이 특정 순서에 편향되는것을 방지 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add18db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 모델을 이용하여 형태소 분석 \n",
    "sp = spm.SentencePieceProcessor()\n",
    "# 생성된 모델을 로드 \n",
    "sp.load('ko_unigram.model')\n",
    "text = '나는 학교에 간다'\n",
    "print(sp.encode(text, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▁ 특수 기호는 키보드 입력이 불가 \n",
    "char = '\\u2581'\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98de17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(sp.encode(t, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfa910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c395f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(komoran.morphs(text))  # 형태소 나열\n",
    "print(komoran.pos(text))    # (행태소, 동사) 튜플 나열\n",
    "print(komoran.nouns(text))  # 명사만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3708a",
   "metadata": {},
   "source": [
    "### komoran 동사를 일반적으로 사용하는 것들 \n",
    "- 감성/의도 분석/리뷰 (가장 일반적)\n",
    "    - NNG(일반명사), NNP(고유명사), VV(동사), VA(형용사), MAG(일반부사), SL(외국어)\n",
    "- 명사 기반의 분류 (문서에 대한 분류 작업)\n",
    "    - NNG(일반명사), NNP(고유명사), NR(수사), NP(대명사)\n",
    "- 의미가 있는 단어를 최대한 포함하고 싶은 경우\n",
    "    - NNG(일반명사), NNP(고유명사), VV(동사), VA(형용사), MAG(일반부사), MAJ(접속부사), IC(감탄사), SL(외국어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 형태소의 종류\n",
    "allow_pos = ['NNG', 'NNP', 'VV', 'VA']\n",
    "\n",
    "# 선택한 형태소들을 추출하기 위한 함수를 정의 \n",
    "def komoran_tokenize(text):\n",
    "    # 선택한 형태소만 저장하는 빈 리스트를 생성 \n",
    "    result = []\n",
    "    for morph, pos in komoran.pos(text):\n",
    "        if pos in allow_pos:\n",
    "            result.append(morph)\n",
    "    return result\n",
    "\n",
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(komoran_tokenize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f53ea2",
   "metadata": {},
   "source": [
    "# 백터화 \n",
    "- 토큰화 작업에서 단어들을 추출했다면 해당 단어들을 숫자형으로 변환\n",
    "    - 숫자형태로 변환하는 이유는? -> 컴퓨터가 숫자로만 연산이 가능하기 때문에\n",
    "- 숫자형태로 변환한 데이터를 학습 데이터로 이용, 정답은 lebel 데이터로 규칙을 생성해가는 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding -> 하나의 리뷰에서 특정 단어가 포함되어 있는가?\n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t').dropna()\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ab0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체의 텍스트를 이용해서 학습을 통한 단어를 습득한 뒤 \n",
    "# 해당하는 단어들이 리뷰에 포함되어있는가?\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5266243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "# 존재 여부만 파악 객체 생성\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# 학습을 한 뒤 변환(data 대입) -> 데이터는 document에서 10개의 데이터\n",
    "X = vectorizer.fit_transform(df['document'].head(5))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 단어들이 무엇인가 출력 (단어 사전)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_feature_names_out()의 단어를 포함하고 있는지 확인 \n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff92275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24806275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Okt + CounterVectorizer 같이 사용 -> 토큰화 + 백터화\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# 형태소 변환 함수 정의 \n",
    "def okt_tokenize(text):\n",
    "    # 특정 형태의 단어들만 추출한다. \n",
    "    # 명사, 동사, 형용사만 선택\n",
    "    select_pos = ['Noun', 'Verb', 'Adjective']\n",
    "    # (단어, 형태)를 출력하는 pos() 함수 이용\n",
    "    # result = okt.morphs(text)\n",
    "    result = [ \n",
    "        word for word, pos in okt.pos(text) if pos in select_pos\n",
    "    ]\n",
    "    # 위의 코드의 작동 방식\n",
    "    # result2 = []\n",
    "    # for word, pos in okt.pos(text):\n",
    "    #     if pos in select_pos:\n",
    "    #         result2.append(word)\n",
    "    return result\n",
    "\n",
    "# CounterVertorizer 생성 \n",
    "vectorizer_okt = CountVectorizer(\n",
    "    tokenizer= okt_tokenize, \n",
    "    lowercase= False, \n",
    "    binary=True\n",
    ")\n",
    "\n",
    "x_okt = vectorizer_okt.fit_transform(df['document'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "138d4111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가볍지' '교도소' '구먼' '늙어' '다그' '더빙' '던스트' '돋보였던' '래서' '목소리' '몬페' '무재' '밓었'\n",
      " '보고' '보는것을' '보였다' '보이기만' '솔직히' '스파이더맨' '않구나' '없다' '연기' '영화' '오버' '의' '이뻐'\n",
      " '이야기' '익살스런' '재미' '조정' '줄' '진짜' '짜증나네요' '초딩' '추천' '커스틴' '평점' '포스터' '했던'\n",
      " '흠']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_okt.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_okt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6063d3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가볍지</th>\n",
       "      <th>교도소</th>\n",
       "      <th>구먼</th>\n",
       "      <th>늙어</th>\n",
       "      <th>다그</th>\n",
       "      <th>더빙</th>\n",
       "      <th>던스트</th>\n",
       "      <th>돋보였던</th>\n",
       "      <th>래서</th>\n",
       "      <th>목소리</th>\n",
       "      <th>...</th>\n",
       "      <th>줄</th>\n",
       "      <th>진짜</th>\n",
       "      <th>짜증나네요</th>\n",
       "      <th>초딩</th>\n",
       "      <th>추천</th>\n",
       "      <th>커스틴</th>\n",
       "      <th>평점</th>\n",
       "      <th>포스터</th>\n",
       "      <th>했던</th>\n",
       "      <th>흠</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   가볍지  교도소  구먼  늙어  다그  더빙  던스트  돋보였던  래서  목소리  ...  줄  진짜  짜증나네요  초딩  추천  \\\n",
       "0    0    0   0   0   0   1    0     0   0    1  ...  0   1      1   0   0   \n",
       "1    1    0   0   0   0   0    0     0   0    0  ...  1   0      0   1   0   \n",
       "2    0    0   0   0   1   0    0     0   1    0  ...  0   0      0   0   1   \n",
       "3    0    1   1   0   0   0    0     0   0    0  ...  0   0      0   0   0   \n",
       "4    0    0   0   1   0   0    1     1   0    0  ...  0   0      0   0   0   \n",
       "\n",
       "   커스틴  평점  포스터  했던  흠  \n",
       "0    0   0    0   0  0  \n",
       "1    0   0    1   0  1  \n",
       "2    0   0    0   0  0  \n",
       "3    0   1    0   0  0  \n",
       "4    1   0    0   1  0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    x_okt.toarray(), \n",
    "    columns= vectorizer_okt.get_feature_names_out()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
