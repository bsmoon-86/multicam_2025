{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303e7fcc",
   "metadata": {},
   "source": [
    "# 랜덤포레스트 \n",
    "- Bagging의 확장판\n",
    "- Bagging의 데이터 샘플링 방식 + 다수결 / 평균을 사용\n",
    "- 각 노드에서 분할 할때 모든 특성(피쳐) 중 일부만 무작위 선택 -> 트리간의 상관성 낮춰준다. 다양성 증가 \n",
    "- 여러 결정 트리를 서로 다르게 학습 시킨뒤 투표(분류) 또는 평균(회귀)으로 예측하는 Bagging 기반의 앙상블 모델 \n",
    "- 부트스트랩 샘플링(중복 허용 데이터셋)과 특성 무작위로 선택으로 모델간의 상관성을 줄여 성능과 안정성 높이는 방법\n",
    "- 고차원 데이터에서 안정성 \n",
    "- 대부분의 실무에서 많이 사용이 되는 알고리즘 \n",
    "\n",
    "- 매개변수 \n",
    "    - n_estimators\n",
    "        - 기본값 : 100\n",
    "        - 모델의 생성 개수\n",
    "    - criterion\n",
    "        - 분류 : gini(기본값), entropy, log_loss\n",
    "        - 회귀 : squared_error(기본값), absolute_error, friedman_mse, poisson\n",
    "    - max_depth\n",
    "        - 기본값 : None\n",
    "        - 트리의 최대 깊이\n",
    "    - bootstrap\n",
    "        - 기본값 : True\n",
    "        - 트리 학습에서 부트스트랩을 사용 여부 \n",
    "    - max_features\n",
    "        - 분류의 기본값 : \"sqrt\" (피쳐의 개수의 루트 값)\n",
    "        - 회귀의 기본값 : 1.0 (모든 피쳐)\n",
    "        - 가능한 값 : int, float(0~1), 'sqrt', 'log2'\n",
    "    - min_sample_leaf  \n",
    "        - 기본값 : 1\n",
    "        - 리프노드의 최소의 샘플수 \n",
    "        - 값을 크면 -> 리프가 너무 세분화되는 것을 방지하여 과적합 방지 \n",
    "    - max_leaf_node\n",
    "        - 기본값 : None\n",
    "        - 트리 전체에서 리프 노드의 개수 제한 \n",
    "        - 너무 많은 리프 생성 -> 과적합 \n",
    "        - 너무 적은 리프 생성 -> 단순화되어 성능 저하 \n",
    "    - min_weight_fraction_leaf\n",
    "        - 기본값 : 0.0\n",
    "        - 샘플 가중치의 합이 전체 데이터에서 차지하는 최소의 비율\n",
    "        - 불균형 데이터셋에서 유용\n",
    "    - oob_score\n",
    "        - 기본값 : False\n",
    "        - 부트스트랩에서 빠진 샘플을 이용하여 검증 점수를 추정 \n",
    "    - max_samples\n",
    "        - 기본값 : None\n",
    "        - bootstrap이 True일 때, 각 트리가 사용할 샘플 수(비율)\n",
    "- 속성\n",
    "    - estimators_\n",
    "        - 개별 결정트리들의 리스트 \n",
    "    - feature_importances_\n",
    "        - 피쳐들의 중요도 \n",
    "    - n_feature_in_ / feature_names_in_\n",
    "        - 입력이 되는 피쳐의 개수 / 입력이 되는 피쳐의 이름들\n",
    "    - oob_score_\n",
    "        - OOB 점수 (oob_score 매개변수가 True 일때)\n",
    "    - oob_decision_function_\n",
    "        - 분류 사용 가능\n",
    "        - OOB 데이터들의 확률/결정함수\n",
    "    - oob_prediction_\n",
    "        - 회귀 사용가능\n",
    "        - OOB 예측값\n",
    "- 메서드 \n",
    "    - fit(x, y)\n",
    "        - 모델의 학습\n",
    "    - predict(x)\n",
    "        - 예측 값 출력\n",
    "    - score(x, y)\n",
    "        - 분류에서는 정확도, 회귀에서는 r2score\n",
    "    - apply(x)\n",
    "        - 각 샘플이 각 트리에서 도달하는 리프 인덱스를 변환 \n",
    "    - decision_path(x)\n",
    "        - 트리 내의 경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, \\\n",
    "    recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = pd.read_csv(\"../data/bodyPerformance.csv\")\n",
    "body['gender'] = np.where(body['gender'] == 'M', 0, 1)\n",
    "body['class'] = body['class'].map(\n",
    "    {\n",
    "        'A' : 0, \n",
    "        'B' : 1, \n",
    "        'C' : 2, \n",
    "        'D' : 3\n",
    "    }\n",
    ")\n",
    "feature_names = body.columns.difference(['class'])\n",
    "x = body[feature_names].values\n",
    "y = body['class']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3, random_state=42, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 모델을 생성 \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터에서 다중 클래스 분류 -> 정밀도, 재현율 f1socre를 생성할때는 average의 값을 변경 \n",
    "cm  = confusion_matrix(Y_test, pred)\n",
    "acc = accuracy_score(Y_test, pred)\n",
    "prc = precision_score(Y_test, pred, average='micro')\n",
    "rcll = recall_score(Y_test, pred, average='micro')\n",
    "f1 = f1_score(Y_test, pred, average='micro')\n",
    "\n",
    "print(cm)\n",
    "print(\"정확도 : \", round(acc, 2))\n",
    "print(\"정밀도 : \", round(prc, 2))\n",
    "print(\"재현율 : \", round(rcll, 2))\n",
    "print('f1score : ', round(f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de62ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 분류 모델의 성능을 개선하기 위해서 하이퍼파라미터를 수정 \n",
    "# 학습할 트리의 개수를 200개 증가 \n",
    "# 노드 분할에 필요한 최소 샘플 수는 기본값 2 -> 4 변환\n",
    "# 트리 전체에서 리프 노드의 최대 개수의 제한을 10개 변환\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators= 200, \n",
    "    min_samples_split=4, \n",
    "    max_leaf_nodes=20\n",
    ")\n",
    "clf2.fit(X_train, Y_train)\n",
    "print(\n",
    "    round(\n",
    "        clf2.score(X_test, Y_test), 2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.read_csv('../data/CarPrice_Assignment.csv')\n",
    "car_num = car.select_dtypes('number')\n",
    "\n",
    "feature_names = car_num.columns.difference(['car_ID', 'syboling', 'price'])\n",
    "\n",
    "x = car_num[feature_names].values\n",
    "y = car_num['price'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor()\n",
    "reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ddf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(Y_test, pred)\n",
    "mse = mean_squared_error(Y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, pred)\n",
    "\n",
    "print('MAE : ' , round(mae, 2))\n",
    "print('MSE : ', round(mse, 2))\n",
    "print('RMSE : ', round(rmse, 2))\n",
    "print('R2score : ', round(r2, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
