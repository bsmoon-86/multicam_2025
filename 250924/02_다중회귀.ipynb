{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faa1c77",
   "metadata": {},
   "source": [
    "# 다중 회귀 \n",
    "- 다중의 독립 변수가 존재하는 회귀 분석 \n",
    "- 여러 개의 독립 변수가 복합적으로 종속 변수에 영향을 미치는 경우 다중 회귀 모형으로 데이터를 예측\n",
    "- 다중 회귀에서 최적의 모델을 결정하기 위해 여러 가지의 방법이 존재 \n",
    "- 모델이 복잡해지면 과대적합이 발생할 가능성이 있기 때문에 이를 방지하기 위해 다양한 규제 방식이 존재하고 규제에 따른 모델들이 존재 \n",
    "    - 모델에서 규제 방식에 따라서 가중치를 제한\n",
    "    - 독립 변수에서의 가중치가 0이 되는 차원(컬럼 | 피쳐)들이 생성 \n",
    "    - 규제를 강하게 걸면 가중치의 절대치가 줄어들고 0에 가까워진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb4e43",
   "metadata": {},
   "source": [
    "## 릿지 \n",
    "- 최소제곱 적합식의 수축 패널티라 불리는 항에 L2 패널티를 추가한것 \n",
    "\n",
    "- 매개변수 \n",
    "    - alpha\n",
    "        - 기본값 : 1.0\n",
    "        - 규제의 강도 -> 클수록 회귀 계수가 작아지고 과적합의 방지, 과소적합 위험\n",
    "        - 해당 모델의 중요한 매개변수\n",
    "    - solver\n",
    "        - 기본값 : 'auto'\n",
    "        - 해를 구하는 방법 \n",
    "        - 데이터의 크기 / 희소성에 따라 적합한 solver를 선택 \n",
    "        - 'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'\n",
    "            - svd : 특이값 분해, 다중공선성 있고 데이터의 개수가 작거나 중간 정도 \n",
    "            - cholesky : 정규방정식, 데이터의 개수가 작거나 중간 정도 \n",
    "            - lsqr : 반복 최소제곱, 대규모 데이터중 희소/밀집 데이터\n",
    "            - sparse_cg : 공액 기울기법, 대규모 데이터 중 희소 데이터 \n",
    "            - sag : 확률적 평균 검사, 데이터의 행의 수가 열의 수보다 월등히 많은 경우\n",
    "            - saga : sag 확장, 대규모 희소, ElasticNet 가능\n",
    "    - tol\n",
    "        - 기본값 : 0.001 (1e-03)\n",
    "        - 수렴의 판단 기준, 작을수록 정밀, 속도적인 면에서 느려질수 있다. \n",
    "    - max_iter\n",
    "        - 기본값 : None\n",
    "        - 최적화 될때까지 최대 반복 횟수.(데이터 크거나 수치가 불안정 경우에 필요)\n",
    "    \n",
    "- 속성 \n",
    "    - coef_\n",
    "        - 회귀 계수를 출력 (규제로 인해서 선형 회귀에 비해 값들이 작게 출력)\n",
    "    - n_iter_\n",
    "        - solver가 반복한 횟수 출력 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d35b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fed46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(diabetes['data'], columns = diabetes['feature_names'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.logspace(-3, 1, 5)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값에 따라 회귀계수가 어떻게 변화하는가?\n",
    "# 반복 실행할때 마다 회귀계수를 추가해주는 빈 리스트 \n",
    "data = []\n",
    "\n",
    "for a in alpha:\n",
    "    # print(a)\n",
    "    # Ridge class 생성 시 alpha 매개변수에 a를 대입\n",
    "    ridge = Ridge(alpha=a)\n",
    "    # 모델 학습 \n",
    "    ridge.fit(df.values, diabetes['target'])\n",
    "    # 학습 된 모델에서 회귀계수를 출력하여 data에 추가 \n",
    "    data.append(\n",
    "        ridge.coef_\n",
    "    )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79569f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ridge =  pd.DataFrame(data, index = alpha, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a75752",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(df_ridge)\n",
    "plt.xticks(alpha, labels=np.log10(alpha))\n",
    "plt.legend(labels=df_ridge.columns, bbox_to_anchor=(1,1))\n",
    "plt.xlabel(alpha)\n",
    "plt.ylabel('coef')\n",
    "plt.axhline(y = 0, color='black', linewidth = 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8300b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 선형 회귀와 릿지 회귀 의 회귀 계수를 확인 \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(\n",
    "    df.values, \n",
    "    diabetes['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b375c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(y = 0, linestyle = '--', linewidth = 3, color = 'black')\n",
    "plt.plot(df_ridge.loc[0.001, ], '^-')\n",
    "plt.plot(df_ridge.loc[0.01, ], 's')\n",
    "plt.plot(df_ridge.loc[0.1], 'v')\n",
    "plt.plot(df_ridge.loc[1.0], '*')\n",
    "plt.plot(df_ridge.loc[10.0], 'o-')\n",
    "plt.plot(lr.coef_, 'r', linewidth=3, alpha=0.5)\n",
    "plt.legend( ['cneter', 0.001, 0.01, 0.1, 1, 10, 'linear'], bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b313ecc",
   "metadata": {},
   "source": [
    "- 연습 \n",
    "    - train과 test의 비율은 8:2로 분할\n",
    "    - 당뇨 데이터를 이용하여 단순 선형 회귀를 이용하여 학습, 평가를 하여 평가 지표 mse값을 확인하고 \n",
    "    - 릿지 회귀를 이용하여 alpha 0.01, 0.1, 1 인 경우로 학습, 평가를 하여 평가 지표 mse값을 확인하여 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ae84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수, 종속변수 각각 x, y에 대입\n",
    "x = df.values\n",
    "y = diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ebee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수, 종속 변수 데이터를 train, test로 8:2의 비율이 나눠준다. \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, test_size= 0.2 , random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e293e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 선형 회귀 class를 생성 \n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 이용하여 모델의 학습\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표를 확인하기 위해 metrics 안에 있는 mse, r2score 로드\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f70abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값에 따라 모델을 여러개 생성\n",
    "ridge_1 = Ridge(alpha=0.01)\n",
    "ridge_2 = Ridge(alpha=0.1)\n",
    "ridge_3 = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d332da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 모델에 학습 데이터를 대입하여 학습\n",
    "ridge_1.fit(X_train, Y_train)\n",
    "ridge_2.fit(X_train, Y_train)\n",
    "ridge_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba984243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 모델들을 이용하여 예측용 독립 변수를 대입하여 예측 값을 저장 \n",
    "lr_pred = lr.predict(X_test)\n",
    "ridge_1_pred = ridge_1.predict(X_test)\n",
    "ridge_2_pred = ridge_2.predict(X_test)\n",
    "ridge_3_pred = ridge_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE -> 오차를 제곱하여 평균을 낸 평가 지표\n",
    "mse_lr = mean_squared_error(Y_test, lr_pred)\n",
    "mse_ridge_1 = mean_squared_error(Y_test, ridge_1_pred)\n",
    "mse_ridge_2 = mean_squared_error(Y_test, ridge_2_pred)\n",
    "mse_ridge_3 = mean_squared_error(Y_test, ridge_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c120892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(mse_lr, 2))\n",
    "print(round(mse_ridge_1, 2))\n",
    "print(round(mse_ridge_2, 2))\n",
    "print(round(mse_ridge_3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lr = r2_score(Y_test, lr_pred)\n",
    "r2_ridge_1 = r2_score(Y_test, ridge_1_pred)\n",
    "r2_ridge_2 = r2_score(Y_test, ridge_2_pred)\n",
    "r2_ridge_3 = r2_score(Y_test, ridge_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(r2_lr, 4))\n",
    "print(round(r2_ridge_1, 4))\n",
    "print(round(r2_ridge_2, 4))\n",
    "print(round(r2_ridge_3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ffa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test의 첫번째 인덱스의 값\n",
    "X_test[0]\n",
    "# 선형 회귀 계수\n",
    "lr.coef_\n",
    "# 절편\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cea652",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 절편 값을 저장\n",
    "pred_1 = lr.intercept_\n",
    "for w, x in zip(lr.coef_, X_test[0]):\n",
    "    # pred_1에 w와 x를 곱한 값을 누적합 \n",
    "    pred_1 += (w * x)\n",
    "\n",
    "pred_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea433d",
   "metadata": {},
   "source": [
    "## 라쏘\n",
    "- 최소 제곱 적합식의 수축 패널티라 불리는 항에 L1 패널티를 추가한 것 \n",
    "- 릿지 회귀가 변수의 크기가 매우 큰 데이터인 경우에는 결과를 해석하는데 어려움 발생하는데 이러한 문제를 해결하기위한 방법 \n",
    "\n",
    "- 매개변수 \n",
    "    - alpha\n",
    "        - 기본값 : 1.0 \n",
    "        - 규제 강도. 클수록 많은 회귀 계수가 0이 되어 변수 선택(feature select)\n",
    "        - 규제의 강도가 너무 큰 경우에는 많은 컬럼의 회귀 계수가 0이 되어 단순한 데이터(과소적합)\n",
    "    - seletion\n",
    "        - 기본값 : 'cyclic'\n",
    "        - 좌표축 경사법 업데이트의 순서 \n",
    "            - cyclic : 순차적으로 업데이트\n",
    "            - random : 무작위 선택 업데이트 \n",
    "        - 피쳐의 순서대로 가중치를 적용할것인가? 아니면 무작위 선택으로 가중치를 적용할 것인가?\n",
    "    - percompute\n",
    "        - 기본값 : auto\n",
    "        - Gram matrix의 미리 계산의 여부\n",
    "        - 그람 행렬은 선형 대수에서 자주 쓰이는 개념\n",
    "        - 회귀 분석에서 핵심적인 부분 \n",
    "    - warm_start\n",
    "        - 기본값 : False\n",
    "        - 이전의 학습 결과를 이어서 학습을 할지 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha의 범위를 하나 지정 \n",
    "alpha = np.logspace(-3, 1, 5)\n",
    "# 모델이 학습을 하고 생성된 회귀 계수를 추가하는 공간인 빈 리스트 생성 \n",
    "data = []\n",
    "\n",
    "for a in alpha:\n",
    "    # print(a)\n",
    "    lasso = Lasso(alpha = a)\n",
    "    # 모델 학습 \n",
    "    lasso.fit(df.values, diabetes['target'])\n",
    "    data.append(lasso.coef_)\n",
    "\n",
    "lasso_df = pd.DataFrame(data, index=alpha, columns = df.columns)\n",
    "lasso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수를 그래프 시각화\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.semilogx(lasso_df)\n",
    "# y = 0 보조선 추가 \n",
    "plt.axhline(y = 0, linestyle = '--', color = 'black', linewidth=3, alpha=0.4)\n",
    "plt.legend(labels = lasso_df.columns, bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7db5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(df.values, diabetes['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3194453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.axhline(y = 0, linestyle='--', linewidth = 3, alpha = 0.3)\n",
    "plt.plot(lasso_df.loc[0.001, ], '^-', label ='Lasso 0.001')\n",
    "plt.plot(lasso_df.loc[0.01, ], 's', label = 'Lasso 0.01')\n",
    "plt.plot(lasso_df.loc[0.1, ], 'v', label = 'Lasso 0.1')\n",
    "plt.plot(lasso_df.loc[1.0, ], '*', label ='Lasso 1.0')\n",
    "plt.plot(lr.coef_, 'r', linewidth=3, alpha = 0.3, label='Linear')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f60921",
   "metadata": {},
   "source": [
    "- 연습 \n",
    "    - train, test  75:25 비율로 생성\n",
    "    - 단순 선형 회귀, Lasso 모델을 이용하여 당뇨병 데이터 학습을 시키고 평가를 하여 평가 지표를 하나 생성 \n",
    "        - Lasso Alpha는 0.01, 0.1 2개의 모델을 생성 \n",
    "    - mse, r2_score의 값들을 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values\n",
    "y = diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96427af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543410e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립, 종속 변수를 데이터 분할 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, test_size= 0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성 \n",
    "lr = LinearRegression()\n",
    "lasso1 = Lasso(alpha=0.01)\n",
    "lasso2 = Lasso(alpha=0.1)\n",
    "lasso3 = Lasso(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae890ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 데이터를 학습 \n",
    "lr.fit(X_train, Y_train)\n",
    "lasso1.fit(X_train, Y_train)\n",
    "lasso2.fit(X_train, Y_train)\n",
    "lasso3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 이용하여 예측\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_lasso1 = lasso1.predict(X_test)\n",
    "pred_lasso2 = lasso2.predict(X_test)\n",
    "pred_lasso3 = lasso3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 mse 생성 \n",
    "mse_lr = mean_squared_error(Y_test, pred_lr)\n",
    "mse_lasso1 = mean_squared_error(Y_test, pred_lasso1)\n",
    "mse_lasso2 = mean_squared_error(Y_test, pred_lasso2)\n",
    "mse_lasso3 = mean_squared_error(Y_test, pred_lasso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(mse_lr, 4))\n",
    "print(round(mse_lasso1, 4))\n",
    "print(round(mse_lasso2, 4))\n",
    "print(round(mse_lasso3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lr = r2_score(Y_test, pred_lr)\n",
    "r2_lasso1 = r2_score(Y_test, pred_lasso1)\n",
    "r2_lasso2 = r2_score(Y_test, pred_lasso2)\n",
    "r2_lasso3 = r2_score(Y_test, pred_lasso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(r2_lr, 4))\n",
    "print(round(r2_lasso1, 4))\n",
    "print(round(r2_lasso2, 4))\n",
    "print(round(r2_lasso3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da65a4",
   "metadata": {},
   "source": [
    "## 엘라스틱넷\n",
    "- 릿지 회귀, 라쏘 회귀를 절충한 알고리즘\n",
    "- L1, L2 패널티를 혼합 -> 혼합의 비율을 지정\n",
    "\n",
    "- 매개변수 \n",
    "    - alpha \n",
    "        - 기본값 : 1\n",
    "        - 전체 규제의 강도 \n",
    "    - l1_ratio\n",
    "        - 기본값 : 0.5\n",
    "        - L1 패널티의 비중 \n",
    "        - 0 : 릿지 회귀\n",
    "        - 1 : 라쏘 회귀 \n",
    "        - 0과 1사이의 값 : 엘라스틱넷\n",
    "- 라쏘가 과도하게 변수를 제거하거나 릿지가 과적합을 충분하게 억제 하지 못하는 경우에 중간의 타협안으로 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d373b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.logspace(-3, 1, 5)\n",
    "\n",
    "data = []\n",
    "\n",
    "for a in alpha:\n",
    "    ela = ElasticNet(alpha = a)\n",
    "    ela.fit(x, y)\n",
    "    data.append(ela.coef_)\n",
    "\n",
    "ela_df = pd.DataFrame(data, index=alpha, columns=df.columns)\n",
    "ela_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a99a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수를 그래프 시각화 \n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.semilogx(ela_df)\n",
    "\n",
    "plt.legend(labels = ela_df.columns, bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.axhline(y = 0, linestyle='--', linewidth=3, alpha=0.4)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘라스틱넷의 alpha에 따라서 실제 모델의 성능을 확인 \n",
    "ela1 = ElasticNet(alpha=0.01)\n",
    "ela2 = ElasticNet(alpha=0.1)\n",
    "ela3 = ElasticNet(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc337b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ela1.fit(X_train, Y_train)\n",
    "ela2.fit(X_train, Y_train)\n",
    "ela3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ela1 = ela1.predict(X_test)\n",
    "pred_ela2 = ela2.predict(X_test)\n",
    "pred_ela3 = ela3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ela1 = mean_squared_error(Y_test, pred_ela1)\n",
    "mse_ela2 = mean_squared_error(Y_test, pred_ela2)\n",
    "mse_ela3 = mean_squared_error(Y_test, pred_ela3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(mse_ela1, 4))\n",
    "print(round(mse_ela2, 4))\n",
    "print(round(mse_ela3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736e669",
   "metadata": {},
   "source": [
    "- 연습 \n",
    "    - sklearn라이브러리 안에 있는 datasets들 중에 fetch_california_housing 함수를 로드 \n",
    "    - 해당 함수를 이용하여 샘플 데이터를 변수에 저장 \n",
    "    - 샘플 데이터에서 독립 변수와 종속 변수를 각각 X, Y 대입하여 저장 \n",
    "    - train, test의 비율은 7:3의 비율로 데이터의 분할 \n",
    "    - 단순 선형 회귀, 엘라스틱넷을 이용하여 모델의 성능을 검증 \n",
    "        - alpha :  0.01, 0.1, 1\n",
    "        - l1_ratio : 0, 0.5, 1\n",
    "    - 평가 지표는 mse을 이용\n",
    "    - 가장 성능이 좋은 모델을 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2551bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03586f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터 로드 \n",
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수 \n",
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a763342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "cali['price'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe84410",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cali 데이터프레임에서 price를 예측하기 위해 price를 제외한 나머지 컬럼들을 독립 변수 \n",
    "# price를 종속 변수\n",
    "x = cali.drop( 'price', axis=1 ).values\n",
    "y = cali['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터들을 train, test로 나눠준다. \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, test_size= 0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 선형 모델 생성 \n",
    "lr  = LinearRegression()\n",
    "# train 데이터를 이용해서 학습 \n",
    "lr.fit(X_train, Y_train)\n",
    "# X_test를 이용하여 데이터를 예측 -> 집값 예측가격을 출력 \n",
    "pred_lr = lr.predict(X_test)\n",
    "# 실제 가격 : Y_test, 예측 가격 : pred_lr\n",
    "# MSE -> Y_test와 pred_lr의 차이에서 제곱을 한 뒤 평균\n",
    "mse_lr = mean_squared_error( Y_test, pred_lr )\n",
    "r2_lr = r2_score(Y_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a076f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_lr)\n",
    "print(r2_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9개의 ElasticNet 모델을 생성 \n",
    "alpha = [0.01, 0.1, 1]\n",
    "ratio = [0, 1, 0.5]\n",
    "model_names = ['Ridge', 'Lasso', 'ElasticNet']\n",
    "\n",
    "# 반복문에서 나온 결과를 저장할수 있는 빈 딕셔너리 생성\n",
    "model_result = dict()\n",
    "\n",
    "# 위의 3개의 리스트를 이용하여 반복문 생성 \n",
    "\n",
    "# 첫번째 반복문에서는 ratio, model_names을 이용하여 반복문 생성 \n",
    "for r, name in zip( ratio, model_names ):\n",
    "    # r -> ratio의 각각의 항목 -> L1패널티 비중\n",
    "    # name -> model_names의 각각의 항목 -> L1패널티 비중에 따른 모델의 이름\n",
    "    \n",
    "    # 규제의 강도인 alpha를 이용해서 반복문 생성 \n",
    "    for a in alpha:\n",
    "        # a -> alpha의 각각의 항목 -> 규제의 강도\n",
    "\n",
    "        # 모델을 생성 \n",
    "        ela = ElasticNet(alpha = a, l1_ratio=r)\n",
    "        # 모델에 학습 \n",
    "        ela.fit(X_train, Y_train)\n",
    "        # 예측 값 생성 \n",
    "        pred_ela = ela.predict(X_test)\n",
    "        # 평가지표 생성 \n",
    "        mse_ela = mean_squared_error(Y_test, pred_ela)\n",
    "        r2_ela = r2_score(Y_test, pred_ela)\n",
    "        # 반복 실행을 할때마다 딕셔너리에 mse, r2를 추가  \n",
    "        model_result[f\"{name}_{a}\"] = [round(mse_ela, 3), round(r2_ela, 3)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7371ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(ratio, model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 선형 회귀 데이터 추가\n",
    "model_result['Linear'] = [round(mse_lr, 3), round(r2_lr, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab110789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(model_result, index = ['MSE', 'R2_score']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values('R2_score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
