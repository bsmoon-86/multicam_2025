{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7d98da",
   "metadata": {},
   "source": [
    "### 연습문제 \n",
    "- Doc2Vec 라이브러리 이용한 감정에 분석 \n",
    "- 데이터는 ratings_train.txt파일을 로드 \n",
    "    - 특수 문자, 2칸 이상의 공백의 문자를 제거하는 문자열 좌우 공백 제거 정규화 함수 \n",
    "    - document 컬럼의 데이터에서 중복 데이터를 제거 \n",
    "    - 빈 텍스트, \" \"가 존재한다면 해당 행 데이터도 제거 \n",
    "    - 상위의 5000개 정도 데이터를 이용\n",
    "- 토큰화 함수 Komoran를 이용\n",
    "    - 필요한 품사 : NNP, NNG, VV, VA, MAG, XR 만을 사용\n",
    "    - 불용어 단어 : 하다, 되다, 이다, 것 , 수, 거 단어들은 제외\n",
    "- 데이터에서 독립(document) , 종속(label) 변수로 데이터를 나눠주고 train, test 데이터셋을 나눠준다 비율은 8:2\n",
    "- Doc2Vec 객체를 생성하여 학습 \n",
    "    - 매개변수 \n",
    "        - vector_size = 200\n",
    "        - window = 5\n",
    "        - min_count = 2\n",
    "        - dm = 1\n",
    "        - negative = 5\n",
    "        - seed = 42\n",
    "        - epochs = 50\n",
    "    - 학습 시키는 데이터는 X_train\n",
    "- X_train, X_test -> 문자열 데이터 -> infer_vector() 함수를 이용해서 임베딩  \n",
    "- 고전 머신러닝 분류 모델을 이용하여 입베딩된 데이터를 독립 변수로 Y의 데이터들을 종속 변수로 학습으로 예측\n",
    "    - 정확도를 확인 \n",
    "    - LogisticRegression(max_iter = 2000, random_state = 42)\n",
    "    - LinearSVC(random_state = 42)\n",
    "    - 두개의 모델을 사용하여 정확도가 좋은 모델을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa182048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada341b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 상황들을 로그에 표시해주는 라이브러리 \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6435648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0dbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150000개의 데이터중 결측치의 개수가 5개 확인 \n",
    "# 결측치의 데이터가 매우 작기때문에 제거 \n",
    "# 제거(drop) + 결측치(na) -> dropna()\n",
    "# dropna() 함수를 Serise에서도 내장, DataFrame 내장\n",
    "df2['document'] = df2['document'].dropna()\n",
    "# df2['document'] 인덱스수 -> 150000\n",
    "# df2['document'].dropna() 인덱스의 수 -> 149995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ad8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[\n",
    "    df2['document'].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba39e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실수가 많은 코드들\n",
    "df2['document'] = df2['document'].dropna()\n",
    "df2 = df2['document'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ffb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 제거 \n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf87c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정규화 함수 \n",
    "def nomalize(text):\n",
    "    # text 매개변수에 들어오는 데이터?\n",
    "        # df에 있는 document 컬럼의 values -> 리뷰 데이터\n",
    "    # str(text) 사용하는 이유는?\n",
    "        # 리뷰의 데이터가 문자가 아닌 경우 문자형으로 변경\n",
    "    text = re.sub(r\"[^가-힣0-9a-zA-Z\\s\\.]\", \" \", str(text))\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['documnet']에서 nomalize 함수를 이용\n",
    "# nomalize에 들어가는 인자는 문자열이 기본\n",
    "# nomalize(df['document']) 잘못된 부분\n",
    "# apply() 함수 -> 데이터프레임에서 사용하는 함수 \n",
    "# map() 함수를 비슷한 기능 각각의 원소들을 추출하여 어떤 작업(함수)들을 하는 기능\n",
    "# df.head(3).apply(lambda x : str(x), axis=1)/\n",
    "# df.head(3).map( lambda x : print(x) )\n",
    "df = df.applymap(nomalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 / 공백 텍스트 존재할수 있다.\n",
    "df.loc[\n",
    "    df['document'].isin( [\"\", \" \"] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cde8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 텍스트 , 공백 텍스트  -> 길이가 1이하 \n",
    "df = df.loc[\n",
    "    df['document'].str.len() > 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ff1f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document에서 중복된 데이터들은 제거 \n",
    "df = df.drop_duplicates('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e000fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 생성 \n",
    "# 특정 품사들만 선택 \n",
    "allow_pos = ['NNP', 'NNG', 'VV', 'VA', 'MAG', 'XR']\n",
    "# 불용어 \n",
    "stop_word = ['하다', '되다', '이다', '것', '수', '거']\n",
    "# Komoran 객체를 생성 \n",
    "komoran = Komoran()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    for word, pos in komoran.pos(text):\n",
    "        # word : 단어\n",
    "        # pos : 품사\n",
    "        if pos in allow_pos and word not in stop_word:\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87f2922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708be384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token화 된 리스트를 데이터프레임에 새로운 컬럼에 추가 \n",
    "tokenize_sentense = [ tokenize(val) for val in df['document'].values ]\n",
    "tokenize_sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b67520b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['document_token'] = tokenize_sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7d7fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>document_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "      <td>[더빙, 진짜, 짜증, 나, 목소리]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "      <td>[포스터, 초딩, 영화, 오버, 연기, 가볍]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "      <td>[교도소, 이야기, 솔직히, 재미, 없, 평점, 조정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[익살, 연기, 돋보이, 영화, 스파이더맨, 늙, 보이, 하, 커스틴 던스트, 너무나]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document label  \\\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리     0   \n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나     1   \n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다     0   \n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정     0   \n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...     1   \n",
       "\n",
       "                                     document_token  \n",
       "0                              [더빙, 진짜, 짜증, 나, 목소리]  \n",
       "1                         [포스터, 초딩, 영화, 오버, 연기, 가볍]  \n",
       "2                                                []  \n",
       "3                    [교도소, 이야기, 솔직히, 재미, 없, 평점, 조정]  \n",
       "4  [익살, 연기, 돋보이, 영화, 스파이더맨, 늙, 보이, 하, 커스틴 던스트, 너무나]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76b2c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 문서에 Tag를 부착\n",
    "def tagged_docs(tokenize_data):\n",
    "    tagged = []\n",
    "    for d_id, toks in enumerate(tokenize_data):\n",
    "        # toks의 길이가 0이라면 -> 학습에서 의미없는 문장\n",
    "        if len(toks) == 0:\n",
    "            continue\n",
    "        tagged.append(\n",
    "            TaggedDocument(\n",
    "                words= toks, tags=f\"DOC_{d_id}\"\n",
    "            )\n",
    "        )\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cf1fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 train,  test 셋으로 나눠준다. \n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state= 42, stratify=df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "987bfb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
