{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7d98da",
   "metadata": {},
   "source": [
    "### 연습문제 \n",
    "- Doc2Vec 라이브러리 이용한 감정에 분석 \n",
    "- 데이터는 ratings_train.txt파일을 로드 \n",
    "    - 특수 문자, 2칸 이상의 공백의 문자를 제거하는 문자열 좌우 공백 제거 정규화 함수 \n",
    "    - document 컬럼의 데이터에서 중복 데이터를 제거 \n",
    "    - 빈 텍스트, \" \"가 존재한다면 해당 행 데이터도 제거 \n",
    "    - 상위의 5000개 정도 데이터를 이용\n",
    "- 토큰화 함수 Komoran를 이용\n",
    "    - 필요한 품사 : NNP, NNG, VV, VA, MAG, XR 만을 사용\n",
    "    - 불용어 단어 : 하다, 되다, 이다, 것 , 수, 거 단어들은 제외\n",
    "- 데이터에서 독립(document) , 종속(label) 변수로 데이터를 나눠주고 train, test 데이터셋을 나눠준다 비율은 8:2\n",
    "- Doc2Vec 객체를 생성하여 학습 \n",
    "    - 매개변수 \n",
    "        - vector_size = 200\n",
    "        - window = 5\n",
    "        - min_count = 2\n",
    "        - dm = 1\n",
    "        - negative = 5\n",
    "        - seed = 42\n",
    "        - epochs = 50\n",
    "    - 학습 시키는 데이터는 X_train\n",
    "- X_train, X_test -> 문자열 데이터 -> infer_vector() 함수를 이용해서 임베딩  \n",
    "- 고전 머신러닝 분류 모델을 이용하여 입베딩된 데이터를 독립 변수로 Y의 데이터들을 종속 변수로 학습으로 예측\n",
    "    - 정확도를 확인 \n",
    "    - LogisticRegression(max_iter = 2000, random_state = 42)\n",
    "    - LinearSVC(random_state = 42)\n",
    "    - 두개의 모델을 사용하여 정확도가 좋은 모델을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa182048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada341b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 상황들을 로그에 표시해주는 라이브러리 \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6435648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0dbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 \n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150000개의 데이터중 결측치의 개수가 5개 확인 \n",
    "# 결측치의 데이터가 매우 작기때문에 제거 \n",
    "# 제거(drop) + 결측치(na) -> dropna()\n",
    "# dropna() 함수를 Serise에서도 내장, DataFrame 내장\n",
    "df2['document'] = df2['document'].dropna()\n",
    "# df2['document'] 인덱스수 -> 150000\n",
    "# df2['document'].dropna() 인덱스의 수 -> 149995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ad8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[\n",
    "    df2['document'].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba39e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실수가 많은 코드들\n",
    "df2['document'] = df2['document'].dropna()\n",
    "df2 = df2['document'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ffb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 제거 \n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf87c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정규화 함수 \n",
    "def nomalize(text):\n",
    "    # text 매개변수에 들어오는 데이터?\n",
    "        # df에 있는 document 컬럼의 values -> 리뷰 데이터\n",
    "    # str(text) 사용하는 이유는?\n",
    "        # 리뷰의 데이터가 문자가 아닌 경우 문자형으로 변경\n",
    "    text = re.sub(r\"[^가-힣0-9a-zA-Z\\s\\.]\", \" \", str(text))\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['documnet']에서 nomalize 함수를 이용\n",
    "# nomalize에 들어가는 인자는 문자열이 기본\n",
    "# nomalize(df['document']) 잘못된 부분\n",
    "# apply() 함수 -> 데이터프레임에서 사용하는 함수 \n",
    "# map() 함수를 비슷한 기능 각각의 원소들을 추출하여 어떤 작업(함수)들을 하는 기능\n",
    "# df.head(3).apply(lambda x : str(x), axis=1)/\n",
    "# df.head(3).map( lambda x : print(x) )\n",
    "df = df.applymap(nomalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 / 공백 텍스트 존재할수 있다.\n",
    "df.loc[\n",
    "    df['document'].isin( [\"\", \" \"] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cde8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 텍스트 , 공백 텍스트  -> 길이가 1이하 \n",
    "df = df.loc[\n",
    "    df['document'].str.len() > 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ff1f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document에서 중복된 데이터들은 제거 \n",
    "df = df.drop_duplicates('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e000fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 생성 \n",
    "# 특정 품사들만 선택 \n",
    "allow_pos = ['NNP', 'NNG', 'VV', 'VA', 'MAG', 'XR']\n",
    "# 불용어 \n",
    "stop_word = ['하다', '되다', '이다', '것', '수', '거']\n",
    "# Komoran 객체를 생성 \n",
    "komoran = Komoran()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    for word, pos in komoran.pos(text):\n",
    "        # word : 단어\n",
    "        # pos : 품사\n",
    "        if pos in allow_pos and word not in stop_word:\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87f2922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708be384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token화 된 리스트를 데이터프레임에 새로운 컬럼에 추가 \n",
    "tokenize_sentense = [ tokenize(val) for val in df['document'].values ]\n",
    "tokenize_sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b67520b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['document_token'] = tokenize_sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7d7fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>document_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "      <td>[더빙, 진짜, 짜증, 나, 목소리]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "      <td>[포스터, 초딩, 영화, 오버, 연기, 가볍]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "      <td>[교도소, 이야기, 솔직히, 재미, 없, 평점, 조정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[익살, 연기, 돋보이, 영화, 스파이더맨, 늙, 보이, 하, 커스틴 던스트, 너무나]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document label  \\\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리     0   \n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나     1   \n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다     0   \n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정     0   \n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...     1   \n",
       "\n",
       "                                     document_token  \n",
       "0                              [더빙, 진짜, 짜증, 나, 목소리]  \n",
       "1                         [포스터, 초딩, 영화, 오버, 연기, 가볍]  \n",
       "2                                                []  \n",
       "3                    [교도소, 이야기, 솔직히, 재미, 없, 평점, 조정]  \n",
       "4  [익살, 연기, 돋보이, 영화, 스파이더맨, 늙, 보이, 하, 커스틴 던스트, 너무나]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 문서에 Tag를 부착\n",
    "def tagged_docs(tokenize_data):\n",
    "    tagged = []\n",
    "    for d_id, toks in enumerate(tokenize_data):\n",
    "        # toks의 길이가 0이라면 -> 학습에서 의미없는 문장\n",
    "        if len(toks) == 0:\n",
    "            continue\n",
    "        tagged.append(\n",
    "            TaggedDocument(\n",
    "                words= toks, tags=[ f\"DOC_{d_id}\" ]\n",
    "            )\n",
    "        )\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cf1fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 train,  test 셋으로 나눠준다. \n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state= 42, stratify=df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "987bfb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2007\n",
       "1    1993\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea8a90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec에서 사용할 데이터는 train_df의 document_token 컬럼의 데이터를 이용\n",
    "tagged_train = tagged_docs(train_df['document_token'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84c98b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3925"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30cd764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec 객체를 생성하여 학습 ( 단어 사전 생성(build_vocab), 학습(train)  )\n",
    "model = Doc2Vec(\n",
    "    documents=tagged_train, \n",
    "    vector_size= 200, \n",
    "    window = 5, \n",
    "    dm = 1, \n",
    "    min_count = 2, \n",
    "    negative = 5, \n",
    "    seed = 42, \n",
    "    epochs= 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01786722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 수동 학습\n",
    "model2 = Doc2Vec(\n",
    "    vector_size= 200, \n",
    "    window = 5, \n",
    "    dm = 1, \n",
    "    min_count = 2, \n",
    "    negative = 5, \n",
    "    seed = 42, \n",
    "    epochs= 50\n",
    ")\n",
    "# 단어 사전을 생성 \n",
    "model2.build_vocab(tagged_train)\n",
    "model2.train(tagged_train, total_examples=len(tagged_train), \n",
    "             epochs = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "273ccfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전의 개수 :  2827\n",
      "단어 사전의 개수 :  2827\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전의 개수 확인  -> 단어별 임베딩 벡터 wv\n",
    "print(\"단어 사전의 개수 : \", len(model.wv))\n",
    "print('단어 사전의 개수 : ', len(model2.wv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "648dd38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3925"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6d5d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 문장을 model에 infer_vector 함수를 이용하여 임베딩\n",
    "def infer_vectors(model, norm_texts, epochs = 50):\n",
    "    # norm_tests : 정규화 처리가 끝난 문서들\n",
    "    # model : 임베딩 모델 \n",
    "    vecs = []\n",
    "\n",
    "    for text in norm_texts:\n",
    "        # text : norm_tests의 각 원소들 대입 \n",
    "        tokens = tokenize(text)\n",
    "        # 토큰화된 데이터가 길이가 0인 경우 \n",
    "        if len(tokens) == 0:\n",
    "            # 비어있는 토큰 데이터는 영벡터 / 평균 벡터로 대체 가능 \n",
    "            # 영벡터로 출력 \n",
    "            # continue\n",
    "            vecs.append( \n",
    "                np.zeros(model.vector_size, dtype=np.float32) )\n",
    "        else:\n",
    "            vec = model.infer_vector(tokens, epochs=epochs)\n",
    "            vecs.append(vec)\n",
    "    return np.vstack(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99af40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = infer_vectors( model, train_df['document'].values )\n",
    "Y_train = train_df['label'].values\n",
    "\n",
    "X_test = infer_vectors(model, test_df['document'].values)\n",
    "Y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa98b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 200)\n",
      "(4000,)\n",
      "(1000, 200)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6852a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀 모델과 선형 서포트벡터 분류 모델에 학습하고 \n",
    "# 정확도 체크하는 함수 \n",
    "def eval_clf(clf, X_tr, Y_tr, X_te, Y_te, model_name):\n",
    "    # clf -> 분류 모델 입력값\n",
    "    # tr -> train data\n",
    "    # te -> test data\n",
    "    # model_name -> 프린트에서 어떤 모델을 사용했는가?\n",
    "    # 모델에 학습 \n",
    "    clf.fit(X_tr, Y_tr)\n",
    "    # 모델을 통한 예측\n",
    "    pred = clf.predict(X_te)\n",
    "    # 정확도 \n",
    "    acc = accuracy_score(Y_te, pred)\n",
    "    print(f\"{model_name} 모델의 정확도는 :\", round(acc, 4))\n",
    "    # class report\n",
    "    clf_report = classification_report(Y_te, pred)\n",
    "    print(f\"{model_name} 모델의 report : \\n\", clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1dfce6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic 모델의 정확도는 : 0.742\n",
      "Logistic 모델의 report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       502\n",
      "           1       0.75      0.73      0.74       498\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "LinearSVC 모델의 정확도는 : 0.754\n",
      "LinearSVC 모델의 report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       502\n",
      "           1       0.77      0.73      0.75       498\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델들을 생성 \n",
    "logi = LogisticRegression(max_iter=2000, random_state=42)\n",
    "eval_clf(logi, X_train, Y_train, X_test, Y_test, \"Logistic\")\n",
    "\n",
    "svc = LinearSVC(random_state=42)\n",
    "eval_clf(svc, X_train, Y_train, X_test, Y_test, \"LinearSVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73a1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
