{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ade3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로드 \n",
    "from konlpy.tag import Komoran\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18065e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 결측치를 제외 \n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4e0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수, 종속 변수 생성\n",
    "X = df['document'][:5000]\n",
    "Y = df['label'][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22568e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e338f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=Y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87428c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d3321",
   "metadata": {},
   "source": [
    "- 파이프라인 생성 \n",
    "    - 백터화(TF-IDF 방식)\n",
    "        - 토큰화 함수(Komoran 형태소 방식) 포함 \n",
    "    - LSA\n",
    "        - TruncatedSVD() 차원 축소를 사용\n",
    "    - Scaler\n",
    "        - StandardScaler를 이용\n",
    "    - Model\n",
    "        - SVC() 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460ed37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "262c2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수 \n",
    "komoran = Komoran()\n",
    "allow_pos = ['NNP', 'NNG', 'VV', 'VA', 'MAG']\n",
    "\n",
    "def tokenize(text):\n",
    "    result = []\n",
    "    for word, pos in komoran.pos(text):\n",
    "        if pos in allow_pos:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "# 백터화 객체 생성\n",
    "vectorizer = TfidfVectorizer(\n",
    "    # 토큰화 방식 \n",
    "    tokenizer= tokenize, \n",
    "    lowercase= False, \n",
    "    min_df = 5, \n",
    "    max_df= 0.8, \n",
    "    ngram_range=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d7c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원 축소 객체 생성 \n",
    "svd = TruncatedSVD(\n",
    "    n_components= 200, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c2a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler \n",
    "scaler = StandardScaler(with_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad61ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(\n",
    "    kernel= 'linear', \n",
    "    random_state=42, \n",
    "    probability=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313bbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 4개의 작업 을 하나의 객체로 연결 \n",
    "pipe = Pipeline(\n",
    "  [\n",
    "      ('vector', vectorizer), \n",
    "      ('lsa', svd), \n",
    "      ('scaler', scaler), \n",
    "      ('model', svc)\n",
    "  ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b7f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 매개변수를 찾기 위해 매개변수들을 지정 \n",
    "# pipe를 이용하게 되면 pipe step의 객체들의 key__parameter : [val1, val2]\n",
    "grid_params = {\n",
    "    \"vector__ngram_range\" : [ (1,1), (1,2) ],\n",
    "    \"lsa__n_components\" : [100, 200], \n",
    "    \"model__C\" : [1.0, 2.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec68b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용하여 각각 매개변수들을 대입하여 \n",
    "# 최적의 매개변수를 찾는다\n",
    "grid = GridSearchCV(\n",
    "    estimator= pipe, \n",
    "    param_grid= grid_params, \n",
    "    cv = 2, \n",
    "    scoring='accuracy', \n",
    "    verbose=1, \n",
    "    # n_jobs=-1   # remote error 발생 시 주석 처리 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1858e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekfla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614f869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
