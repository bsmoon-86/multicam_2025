{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaac7d3c",
   "metadata": {},
   "source": [
    "# RNN (순환 신경망)\n",
    "- 이전의 시점의 정보를 현재 시점에 계산에 반영하는 구조\n",
    "\n",
    "- 첫번째 입력이 들어왔을때 \n",
    "    - 초기의 상태 (h_0 = 0)와 입력에 대한 상태 (h_1)로 계산\n",
    "- 두번째 입력이 들어왔을때\n",
    "    - 이전의 상태 (h_1)과 결합해서 계산 (h_2)\n",
    "- 반복 작업이 완료가 되었을때\n",
    "    - 마지막 상태 (h_T) 생성 \n",
    "\n",
    "- 매개변수 \n",
    "    - input_size \n",
    "        - 각 시점에서 입력의 피쳐의 개수 \n",
    "    - hidden_size\n",
    "        - 은닉층(출력)의 크기 \n",
    "    - num_layers\n",
    "        - 기본값 : 1\n",
    "        - RNN 층의 개수 (층이 깊을수록 복잡한 패턴이 생성)\n",
    "        - 개수가 늘어날수록 시간이 증가하고 과적합의 위험성이 존재\n",
    "        - 1~3 정도 사용을 할때 1부터 개수를 1씩 늘려가면서 사용\n",
    "    - nonlinearity\n",
    "        - 기본값 : 'tanh'\n",
    "        - 비선형 활성화 함수를 선택 \n",
    "    - bias\n",
    "        - 기본값 : True\n",
    "        - 각 가중치에 편향 항을 추가 여부 \n",
    "    - batch_first\n",
    "        - 기본값 : False\n",
    "        - 입력 텐서 첫 차원이 배치인지 여부 \n",
    "    - dropout\n",
    "        - 기본값 : 0.0 \n",
    "        - 층 사이에 드랍아웃의 적용 비율 -> 층이 2개 이상에 사용\n",
    "    - bidirectional\n",
    "        - 기본값 : False\n",
    "        - 양방향 RNN을 사용할지 여부 (순방향 이 기본 , 역방향을 사용할지 지정)\n",
    "\n",
    "- 매개변수의 유의점\n",
    "    - hidden_size\n",
    "        - 너무 적은 경우라면 정보가 부족, 너무 큰 경우에는 과적합 \n",
    "        - 일반적으로는 32 ~ 128\n",
    "    - num_layers\n",
    "        - 시간의 복잡도에 따라 1 ~ 3정도 사용\n",
    "        - 1부터 테스트를 돌려서 교차 검증\n",
    "    - nolinearity\n",
    "        - 'tanh'이 기본 값이 'relu'로 변경하게 되면 시간은 감소할 수 있지만 불안정 \n",
    "    - dropout\n",
    "        - 층이 2개인 경우에 사용\n",
    "        - 과적합 방지를 위해 0.2 ~ 0.5 사용 (권장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b213d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 기본형 \n",
    "# 샘플 데이터를 생성해서 코드 작성 \n",
    "import math\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3e8b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f0f4e7d4f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 일관성 설정 \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694c4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사인 그래프를 생성 + 노이즈 \n",
    "\n",
    "idx = torch.arange(3000).float()\n",
    "data = torch.sin(2 * math.pi * 0.02 * idx) + 0.05 * torch.rand(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95fc25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0441,  0.1711,  0.2678,  ..., -0.3259, -0.2480, -0.0964])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(idx, data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65d7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속성이 있는 시계열데이터를 기준으로 train, test를 8:2의 비율로 나눠준다. \n",
    "# 앞부분 80% , 뒷부분 20%\n",
    "# 전체 데이터의 길이에서 0.8을 곱한 idx의 값이 데이터의 경계\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_data = data[ : split_idx]         # 학습 데이터(구간)\n",
    "test_data = data[split_idx : ]          # 평가 데이터(구간) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c365199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train와 test를 스케일링 \n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_data = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "test_data = scaler.transform(test_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653e5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data들을 torch에서 사용하기 위한 tensor의 형태로 변환 (2차원의 데이터를 1차원의 데이터로 변환)\n",
    "train_data = torch.tensor(train_data.squeeze(-1), dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data.squeeze(-1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea8ca8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    # 단변량 시계열에서 입력 값 정답 값을 만드는 Dataset\n",
    "    def __init__(self, _data, _window):\n",
    "        # _data : (N, ) 형태의 1차원 tensor 데이터\n",
    "        # _window : 과거의 몇개의 데이터를 볼것인가?(구간 설정)\n",
    "        self.data = _data\n",
    "        self.window = _window\n",
    "        # 유효 샘플의 개수는 학습 데이터의 개수는 data의 전체 길이에서 -1\n",
    "        # 입력 데이터는 전체 길이 - 윈도우 \n",
    "        self.n = len(_data) - _window\n",
    "\n",
    "    # __len__(), __getitem__() 두개의 특수 함수들은 \n",
    "    # DataLoder에서 자동으로 호출해서 사용이 되는 부분\n",
    "    def __len__(self):\n",
    "        return max(self.n, 0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 변환\n",
    "        # x -> 입력 데이터 (윈도우의 구간을 나타내는 데이터) --> 문제\n",
    "        # y -> 입력 데이터 다음 행의 데이터  --> 정답\n",
    "        x = self.data[idx : idx + self.window].unsqueeze(-1) # (window, ) -> (window, 1)\n",
    "        y = self.data[idx + self.window].unsqueeze(-1)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17eb9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 생성\n",
    "# 구간 설정 값 \n",
    "window = 50\n",
    "train_ds = WindowDataset(train_data, window)\n",
    "val_ds = WindowDataset(test_data, window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
