{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927f8960",
   "metadata": {},
   "source": [
    "## LSA(잠재 의미 분석)\n",
    "- 문서 안에서 단어 사이의 잠재적인 의미 구조를 추출하는 기법 \n",
    "- TF-IDF 방식은 단어 간의 의미적 유사성을 반영X\n",
    "- TF-IDF 에서 SVD 분해를 하여 단어 간의 의미를 파악\n",
    "- TF-IDF에서 차원 축소( PCA, t-SNE과 같은 축소 기법 중 하나를 사용 )하여 관계성을 확인\n",
    "- LSA 효과 \n",
    "    - 백터 공간의 차원을 줄여서 계산 효율을 증가 (차원 축소)\n",
    "    - '영화', '필름' 비슷한 문맥의 단어를 가까운 백터로 이동(의미 유추) \n",
    "    - 문서들을 주제별로 분류 기능(토픽 분석)\n",
    "\n",
    "- TruncatedSVD(차원 축소 모델)\n",
    "    - 절단된 특이값의 분해\n",
    "    - 고차원 희소 행렬(값이 0인 행렬)을 낮은 차원으로 압축하여 데이터 구조적 의미를 유지 \n",
    "    - 자연어 처리, 추천 시스템, 의미 분석, 잠재적인 토픽 분석 주로 사용\n",
    "\n",
    "    - TF-IDF 행렬은 우선은 고차원 -> 저차원\n",
    "    - 0으로 이루어진 희소행렬들을 구조적인 의미를 유지하면서 값들을 부여 \n",
    "    - 같은 토픽의 문서는 같은 백터 공간에서 가깝게 위치 -> 유사도 기반 자연어 처리에 활용\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd32334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 정의 -> pos 필터 \n",
    "okt = Okt()\n",
    "\n",
    "def tokenize(text):\n",
    "    result = [ word for word, pos in okt.pos(text) \n",
    "              if pos in ['Noun', 'Adjective', 'Verb'] ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a047b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    '이 영화 정말 재미있었다', \n",
    "    '매우 연기가 뛰어나다', \n",
    "    '이 영화 별로다', \n",
    "    '지루한 영화는 보기 어렵다', \n",
    "    '정말 훌륭한 연기였다',\n",
    "    \"연기가 별로라서 지루했다\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f18fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 백터화 \n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=tokenize, \n",
    "    ngram_range=(1, 1), \n",
    "    min_df = 1, \n",
    "    max_df = 0.8, \n",
    "    sublinear_tf=True, \n",
    "    lowercase=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a19e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15047a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD를 이용한 차원 축소 (LSA 적용)\n",
    "lsa = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsa = pd.DataFrame(X_lsa, columns = ['topic1', 'topic2'] )\n",
    "df_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8da47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsa['document'] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b88234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf.get_feature_names_out()\n",
    "components = lsa.components_\n",
    "\n",
    "df_terms = pd.DataFrame(components.T, index = terms, \n",
    "                        columns = ['topic1', 'topic2'])\n",
    "df_terms.sort_values('topic1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fab55",
   "metadata": {},
   "source": [
    "1. ratings_test.txt 파일 로드 \n",
    "2. 결측치제외, id 컬럼 제외\n",
    "3. document의 중복된 데이터를 제거 \n",
    "4. 상위 5000개를 필터 \n",
    "5. 독립 변수, 종속변수 train, test 로 데이터 분할 \n",
    "6. X_train을 이용하여 tdifd, LSA 작업 \n",
    "7. 모델은 SVC 사용하여 학습 및 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ratings_test.txt\", sep='\\t')\n",
    "df.dropna(inplace=True)\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documet 컬럼의 데이터 중 중복 데이터 제거 \n",
    "df.drop_duplicates('document', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립, 종속 변수 생성 \n",
    "X = df['document'].values\n",
    "Y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test로 데이터셋 변경\n",
    "X_tr, X_te, Y_tr, Y_te = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=Y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71682ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train , test 데이터 개수를 줄여준다( 빠른 실행을 위해 )\n",
    "X_tr = X_tr[:5000]\n",
    "X_te = X_te[:1000]\n",
    "Y_tr = Y_tr[:5000]\n",
    "Y_te = Y_te[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2305ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 생성 \n",
    "okt = Okt()\n",
    "\n",
    "def tokenize(text):\n",
    "    return okt.morphs(text)\n",
    "# 백터화\n",
    "vector = TfidfVectorizer(\n",
    "    tokenizer=tokenize, \n",
    "    lowercase= False, \n",
    "    ngram_range=(1,2), \n",
    "    min_df= 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 이용하여 백터화 작업 \n",
    "# X_tr를 이용하여 vector에 학습\n",
    "vector.fit(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_vc = vector.transform(X_tr)\n",
    "# train 데이터로 학습한 변환 모델에 test데이터로 변환 \n",
    "X_te_vc = vector.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(\n",
    "    kernel='linear', \n",
    "    C = 1.0, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf 변환을 한 데이터를 이용하여 SVC 모델에 학습 및 평가 \n",
    "svc.fit(X_tr_vc, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터를 이용하여 예측\n",
    "pred_vc = svc.predict(X_te_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87023a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도, f1 score 확인 \n",
    "acc_vc = accuracy_score(pred_vc, Y_te)\n",
    "f1_vc = f1_score(pred_vc, Y_te)\n",
    "print(f\"TD-IDF 변환 후 학습 정확도 : {round(acc_vc, 4)} f1 : {round(f1_vc, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7635b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_vc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA 정의 \n",
    "lsa = TruncatedSVD(\n",
    "    n_components= 200, \n",
    "    random_state= 42\n",
    ")\n",
    "# lsa를 이용하여 학습 \n",
    "lsa.fit(X_tr_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bfa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_lsa = lsa.transform(X_tr_vc)\n",
    "X_te_lsa = lsa.transform(X_te_vc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dadf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_tr_lsa, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26631ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svc = svc.predict(X_te_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lsa = accuracy_score(pred_svc, Y_te)\n",
    "f1_lsa = f1_score(pred_svc, Y_te)\n",
    "\n",
    "print(f'LSA 작업 후 정확도 : {round(acc_lsa, 4)}, f1 : {round(f1_lsa, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler(with_mean= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07085f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_std = std.fit_transform(X_tr_lsa)\n",
    "X_te_std = std.transform(X_te_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44204349",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_tr_std, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_std = svc.predict(X_te_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bf17538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD-IDF -> LSA -> Scaler 작업 후 정확도 : 0.745 f1 : 0.7341\n"
     ]
    }
   ],
   "source": [
    "acc_std = accuracy_score(pred_std, Y_te)\n",
    "f1_std = f1_score(pred_std, Y_te)\n",
    "\n",
    "print(f'TD-IDF -> LSA -> Scaler 작업 후 정확도 : {round(acc_std, 4)} f1 : {round(f1_std, 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
